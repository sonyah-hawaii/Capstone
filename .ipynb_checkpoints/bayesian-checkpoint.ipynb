{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonyahseiden/anaconda3/envs/capstone_env/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n",
      "/Users/sonyahseiden/anaconda3/envs/capstone_env/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "from pymc3 import Model, Normal, HalfNormal, SkewNormal\n",
    "from pymc3 import find_MAP\n",
    "from pymc3 import NUTS, sample\n",
    "from scipy import optimize\n",
    "from pymc3 import traceplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "abatement_historical = pd.read_csv('../data/Data/abatement_calculations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abatement_historical.set_index('country', inplace=True)\n",
    "abatement_historical = abatement_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating subsets based on labels\n",
    "group_1 = abatement_historical[abatement_historical.label==1]\n",
    "group_2 = abatement_historical[abatement_historical.label==2]\n",
    "group_3 = abatement_historical.loc[(abatement_historical.label==0)\n",
    "                                         |(abatement_historical.label==3)\n",
    "                                        |(abatement_historical.label==4)]\n",
    "group_4 = abatement_historical[abatement_historical.label==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to avoid errors I have to remove Saudia Arabia and UAE from our cohort.\n",
    "#They have a steady history of 0 abatement, so they won't be able to work within the bayesian regression, and will affect results of the traditional regressions\n",
    "group_1.drop(['Saudi Arabia', 'United Arab Emirates', 'Kuwait'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking out the distributions of each grouping\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.distplot(group_1.drop('label', axis=1).T.var());\n",
    "plt.title('group 1 variance distribution');\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.distplot(group_2.drop('label', axis=1).T.var());\n",
    "plt.title('group 2 variance distribution');\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.distplot(group_3.drop('label', axis=1).T.var(), bins=5);\n",
    "plt.title('group 3 variance distribution');\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sns.distplot(group_4.drop('label', axis=1).T.var(), bins=8);\n",
    "plt.title('group 4 variance distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Regression Development\n",
    "<a id='bayesian_development'></a>\n",
    "\n",
    "This process was adapted from a notebook developd by Phillippa Thomson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y_{t} = \\beta_0 + \\sum_{i=1}^{t}\\beta_i y_{t-i} +  \\sum_{i=1}^{N}\\beta_j x_{ji} + \\epsilon_i$$ \n",
    "\n",
    "   \n",
    "$$\\beta_0 \\sim Skew Normal(1.75, 1)$$\n",
    "\n",
    "$$\\beta_1 \\sim Skew Normal(1.75, 1)$$\n",
    "\n",
    "$$\\epsilon \\sim Half Normal(1, 0)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Regression for Cohort 1\n",
    "<a id='bayesian'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN THIS CELL AT YOUR OWN RISK (long print out and takes forever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = 100.64, ||grad|| = 11.61: 100%|| 17/17 [00:00<00:00, 1315.78it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:10<00:00, 541.49it/s]\n",
      "100%|| 5500/5500 [00:09<00:00, 581.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 1 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -431.44, ||grad|| = 0.98678: 100%|| 35/35 [00:00<00:00, 1625.34it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:12<00:00, 425.09it/s]\n",
      "100%|| 5500/5500 [00:11<00:00, 495.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 2 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -415.88, ||grad|| = 0.0015831: 100%|| 33/33 [00:00<00:00, 1643.50it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:12<00:00, 456.22it/s]\n",
      "100%|| 5500/5500 [00:11<00:00, 464.95it/s]\n",
      "The acceptance probability does not match the target. It is 0.8966583599989671, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -124.39, ||grad|| = 0.26666: 100%|| 24/24 [00:00<00:00, 1419.47it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:09<00:00, 568.01it/s]\n",
      "100%|| 5500/5500 [00:09<00:00, 572.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 4 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -385.19, ||grad|| = 0.086595: 100%|| 34/34 [00:00<00:00, 1685.10it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:12<00:00, 427.30it/s]\n",
      "100%|| 5500/5500 [00:11<00:00, 479.97it/s]\n",
      "The acceptance probability does not match the target. It is 0.8827912155632334, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 5 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -272.39, ||grad|| = 31.76: 100%|| 31/31 [00:00<00:00, 1847.63it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:11<00:00, 459.17it/s]\n",
      "100%|| 5500/5500 [00:10<00:00, 523.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 6 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -400.43, ||grad|| = 0.20581: 100%|| 35/35 [00:00<00:00, 1660.66it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:12<00:00, 430.76it/s]\n",
      "100%|| 5500/5500 [00:10<00:00, 512.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 7 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -630.89, ||grad|| = 0.0077657: 100%|| 42/42 [00:00<00:00, 1657.78it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:13<00:00, 416.75it/s]\n",
      "100%|| 5500/5500 [00:10<00:00, 506.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 8 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -281.34, ||grad|| = 0.033328: 100%|| 34/34 [00:00<00:00, 1533.19it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:12<00:00, 425.76it/s]\n",
      "100%|| 5500/5500 [00:09<00:00, 552.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 9 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -285.73, ||grad|| = 3.2524e-05: 100%|| 32/32 [00:00<00:00, 1584.25it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:10<00:00, 514.25it/s]\n",
      "100%|| 5500/5500 [00:10<00:00, 516.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 10 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -431.66, ||grad|| = 5.3176: 100%|| 37/37 [00:00<00:00, 1711.75it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:14<00:00, 382.39it/s]\n",
      "100%|| 5500/5500 [00:11<00:00, 476.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 11 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -162.54, ||grad|| = 141.03: 100%|| 40/40 [00:00<00:00, 1589.19it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:11<00:00, 488.86it/s]\n",
      "100%|| 5500/5500 [00:10<00:00, 503.95it/s]\n",
      "The acceptance probability does not match the target. It is 0.8794211034192878, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 12 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -361.41, ||grad|| = 22.185: 100%|| 37/37 [00:00<00:00, 1657.58it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:13<00:00, 416.72it/s]\n",
      "100%|| 5500/5500 [00:11<00:00, 498.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 13 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -228.1, ||grad|| = 17.029: 100%|| 29/29 [00:00<00:00, 1660.75it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:10<00:00, 504.43it/s]\n",
      "100%|| 5500/5500 [00:09<00:00, 561.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 14 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -438.63, ||grad|| = 0.20333: 100%|| 35/35 [00:00<00:00, 1604.69it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:10<00:00, 534.32it/s]\n",
      "100%|| 5500/5500 [00:10<00:00, 546.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 15 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -477.99, ||grad|| = 0.015864: 100%|| 33/33 [00:00<00:00, 1504.23it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:11<00:00, 476.41it/s]\n",
      "100%|| 5500/5500 [00:09<00:00, 554.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 16 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -382.47, ||grad|| = 0.063835: 100%|| 34/34 [00:00<00:00, 1599.84it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:12<00:00, 445.55it/s]\n",
      "100%|| 5500/5500 [00:11<00:00, 474.65it/s]\n",
      "The acceptance probability does not match the target. It is 0.8859463721907985, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 17 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -176.76, ||grad|| = 41.456: 100%|| 31/31 [00:00<00:00, 1171.58it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:12<00:00, 428.87it/s]\n",
      "100%|| 5500/5500 [00:10<00:00, 504.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 18 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -554.07, ||grad|| = 4.2204: 100%|| 35/35 [00:00<00:00, 1309.54it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:13<00:00, 416.64it/s]\n",
      "100%|| 5500/5500 [00:12<00:00, 446.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 19 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -311.57, ||grad|| = 0.00061636: 100%|| 33/33 [00:00<00:00, 1551.11it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:14<00:00, 391.33it/s]\n",
      "100%|| 5500/5500 [00:10<00:00, 507.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 20 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -302.8, ||grad|| = 13.943: 100%|| 30/30 [00:00<00:00, 1743.27it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:11<00:00, 485.30it/s]\n",
      "100%|| 5500/5500 [00:11<00:00, 471.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 21 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -564.84, ||grad|| = 19.065: 100%|| 38/38 [00:00<00:00, 1159.70it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:13<00:00, 418.47it/s]\n",
      "100%|| 5500/5500 [00:10<00:00, 509.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 22 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -254.73, ||grad|| = 9.6835: 100%|| 29/29 [00:00<00:00, 1701.97it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:12<00:00, 428.61it/s]\n",
      "100%|| 5500/5500 [00:10<00:00, 530.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 23 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -457.7, ||grad|| = 31.467: 100%|| 39/39 [00:00<00:00, 1673.76it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:12<00:00, 442.08it/s]\n",
      "100%|| 5500/5500 [00:12<00:00, 433.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 24 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -299.9, ||grad|| = 35.073: 100%|| 31/31 [00:00<00:00, 1418.34it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 5500/5500 [00:13<00:00, 414.21it/s]\n",
      "100%|| 5500/5500 [00:10<00:00, 517.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 25 done\n"
     ]
    }
   ],
   "source": [
    "#building lagged dataframe and running it through a regression\n",
    "train_yi = []\n",
    "train_preds_mean = []\n",
    "train_preds_median = []\n",
    "\n",
    "test_yi = []\n",
    "test_preds_mean = []\n",
    "test_preds_median = []\n",
    "\n",
    "counter = 0\n",
    "for i in group_1.index:\n",
    "    counter += 1\n",
    "    dataset = pd.DataFrame()\n",
    "    dataset['target'] = group_1[group_1.index==i].T.iloc[:,0]\n",
    "    for n in range(1, 16):\n",
    "        dataset[f'lag{n}'] = dataset['target'].shift(n)\n",
    "    dataset = dataset.loc['2005':]\n",
    "    train = dataset[0:-2]\n",
    "    test = dataset[-2:-1]\n",
    "    \n",
    "    #setting up train, val, test\n",
    "    train_target = train['target']\n",
    "    for y in train_target:\n",
    "        train_yi.append(y)\n",
    "    test_target = test['target']\n",
    "    for h in test_target:\n",
    "        test_yi.append(h)\n",
    "\n",
    "    #setting up x and y for MCMC\n",
    "    y = np.array(train_target).reshape(-1,1)\n",
    "    X = train.drop('target', axis=1)\n",
    "    ss = StandardScaler()\n",
    "    X = ss.fit_transform(X)\n",
    "\n",
    "    #setting standard deviation to feed into the mcmc model\n",
    "    mcmc_std = train_target.std()\n",
    "    \n",
    "    #Building model\n",
    "    basic_model = Model()\n",
    "    with basic_model:\n",
    "        # start by defining distribution for all parameters\n",
    "        # use sd to determine strength of the prior\n",
    "        # big sd is a weak prior\n",
    "        intercept = Normal('intercept', mu=0, sd=mcmc_std)\n",
    "        # the shape on beta is the number of features in the fit\n",
    "        beta = Normal('beta', mu=0, sd=mcmc_std, shape=15)\n",
    "        # sigma is the width of the gaussian around yhat\n",
    "        # (i.e. related to the size of the residuals)\n",
    "        sigma = HalfNormal('sigma', sd=1)\n",
    "\n",
    "        # create a formula for yhat\n",
    "        y_hat = intercept + beta * X\n",
    "\n",
    "        # simulate data as a distribution around yhat\n",
    "        Y_obs = Normal('Y_obs', mu=y_hat, sd=sigma, observed=y)\n",
    "\n",
    "        map_estimate = find_MAP(model=basic_model)\n",
    "    with basic_model:\n",
    "        trace = sample(5000,cores=1) #set to sample twice so your predictions can be compared\n",
    "        \n",
    "    #takes in inputs (X) and generates an entire range of 2000 predictions (y_hat)\n",
    "    preds_train = []\n",
    "    for i in trace:\n",
    "        sigma = i['sigma']\n",
    "        eps = np.random.normal(0, sigma)\n",
    "        y_hat = i['intercept'] + np.matmul(X, i['beta']) + eps\n",
    "        preds_train.append(y_hat)\n",
    "        \n",
    "        \n",
    "    #_____________________________________________________________      \n",
    "        \n",
    "    #generating predictions for the train dataset\n",
    "    avg_preds_train = []\n",
    "    for i in pd.DataFrame(preds_train):\n",
    "        train_preds_mean.append(np.mean(pd.DataFrame(preds_train)[i]))\n",
    "        \n",
    "    median_preds_train = []\n",
    "    for i in pd.DataFrame(preds_train):\n",
    "        train_preds_median.append(np.median(pd.DataFrame(preds_train)[i]))\n",
    "\n",
    "    #setting x and y for test predictions\n",
    "    y_test = np.array(test_target).reshape(-1,1)\n",
    "    X_test = np.array(test.drop('target', axis=1))\n",
    "    ss_test = StandardScaler()\n",
    "    X_test = ss.fit_transform(X_test)\n",
    "    \n",
    "    #generating predictions for the test set\n",
    "    preds_test = []\n",
    "    for i in trace:\n",
    "        sigma = i['sigma']\n",
    "        eps = np.random.normal(0, sigma)\n",
    "        y_hat = i['intercept'] + np.matmul(X_test, i['beta']) + eps\n",
    "        preds_test.append(y_hat)\n",
    "        \n",
    "    avg_preds_test = []\n",
    "    for i in pd.DataFrame(preds_test): \n",
    "        test_preds_mean.append(np.mean(pd.DataFrame(preds_test)[i]))\n",
    "        \n",
    "    median_preds_test = []\n",
    "    for i in pd.DataFrame(preds_test): \n",
    "        test_preds_median.append(np.median(pd.DataFrame(preds_test)[i]))\n",
    "        \n",
    "    print(f'country {counter} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.1059111922183202, -2.104646163988897)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(train_yi, train_preds_mean), r2_score(train_yi, train_preds_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1|Bayesian autoregression|-2.11|0.68|553.65|125.68|\n"
     ]
    }
   ],
   "source": [
    "print(f'|1|Bayesian autoregression-mean|\\\n",
    "{np.round(r2_score(train_yi, train_preds_mean), 2)}|\\\n",
    "{np.round(r2_score(test_yi, test_preds_mean), 2)}|\\\n",
    "{np.round(mean_squared_error(train_yi, train_preds_mean), 2)}|\\\n",
    "{np.round(mean_squared_error(test_yi, test_preds_mean), 2)}|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1|Bayesian autoregression-median|-2.1|0.68|553.43|125.54|\n"
     ]
    }
   ],
   "source": [
    "print(f'|1|Bayesian autoregression-median|\\\n",
    "{np.round(r2_score(train_yi, train_preds_median), 2)}|\\\n",
    "{np.round(r2_score(test_yi, test_preds_median), 2)}|\\\n",
    "{np.round(mean_squared_error(train_yi, train_preds_median), 2)}|\\\n",
    "{np.round(mean_squared_error(test_yi, test_preds_median), 2)}|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building lagged dataframe and running it through a regression\n",
    "train_yi = []\n",
    "train_preds = []\n",
    "\n",
    "test_yi = []\n",
    "test_preds = []\n",
    "\n",
    "for i in group_1.index:\n",
    "    dataset = pd.DataFrame()\n",
    "    dataset['target'] = group_1[group_1.index==i].T.iloc[:,0]\n",
    "    for n in range(1, 16):\n",
    "        dataset[f'lag{n}'] = dataset['target'].shift(n)\n",
    "    dataset = dataset.loc['2005':]\n",
    "    train = dataset[0:-2]\n",
    "    test = dataset[-2:-1]\n",
    "    \n",
    "    #setting up train, val, test\n",
    "    train_target = train['target']\n",
    "    for y in train_target:\n",
    "        train_yi.append(y)\n",
    "    test_target = test['target']\n",
    "    for h in test_target:\n",
    "        test_yi.append(h)\n",
    "\n",
    "    #setting up x and y for MCMC\n",
    "    y = np.array(train_target).reshape(-1,1)\n",
    "    X = train.drop('target', axis=1)\n",
    "    ss = StandardScaler()\n",
    "    X = ss.fit_transform(X)\n",
    "\n",
    "    #setting standard deviation to feed into the mcmc model\n",
    "    mcmc_std = train_target.std()\n",
    "    \n",
    "    #Building model\n",
    "    basic_model = Model()\n",
    "    with basic_model:\n",
    "        # start by defining distribution for all parameters\n",
    "        # use sd to determine strength of the prior\n",
    "        # big sd is a weak prior\n",
    "        intercept = Normal('intercept', mu=0, sd=mcmc_std)\n",
    "        # the shape on beta is the number of features in the fit\n",
    "        beta = Normal('beta', mu=0, sd=mcmc_std, shape=15)\n",
    "        # sigma is the width of the gaussian around yhat\n",
    "        # (i.e. related to the size of the residuals)\n",
    "        sigma = HalfNormal('sigma', sd=1)\n",
    "\n",
    "        # create a formula for yhat\n",
    "        y_hat = intercept + beta * X\n",
    "\n",
    "        # simulate data as a distribution around yhat\n",
    "        Y_obs = Normal('Y_obs', mu=y_hat, sd=sigma, observed=y)\n",
    "\n",
    "        map_estimate = find_MAP(model=basic_model)\n",
    "    with basic_model:\n",
    "        trace = sample(2000,cores=1) #set to sample twice so your predictions can be compared\n",
    "        \n",
    "    #takes in inputs (X) and generates an entire range of 2000 predictions (y_hat)\n",
    "    preds_train = []\n",
    "    for i in trace:\n",
    "        sigma = i['sigma']\n",
    "        eps = np.random.normal(0, sigma)\n",
    "        y_hat = i['intercept'] + np.matmul(X, i['beta']) + eps\n",
    "        preds_train.append(y_hat)\n",
    "\n",
    "    #generating predictions for the train dataset\n",
    "    avg_preds_train = []\n",
    "    for i in pd.DataFrame(preds_train):\n",
    "        avg_preds_train.append(np.mean(preds_train[i]))\n",
    "    \n",
    "    #setting x and y for test predictions\n",
    "    y_test = np.array(test_target).reshape(-1,1)\n",
    "    X_test = np.array(test.drop('target', axis=1))\n",
    "    ss_test = StandardScaler()\n",
    "    X_test = ss.fit_transform(X_test)\n",
    "    \n",
    "     #generating predictions for the test set\n",
    "    preds_test = []\n",
    "    for i in trace:\n",
    "        sigma = i['sigma']\n",
    "        eps = np.random.normal(0, sigma)\n",
    "        y_hat = i['intercept'] + np.matmul(X_test, i['beta']) + eps\n",
    "        preds_test.append(y_hat)\n",
    "    avg_preds_test = []\n",
    "    for i in pd.DataFrame(preds_test):\n",
    "        avg_preds_test.append(np.mean(preds_test[i]))   \n",
    "    train_preds.append([p for p in avg_preds_train])\n",
    "    test_preds.append([q for q in avg_preds_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = []\n",
    "for i in train_preds:\n",
    "    for n in i:\n",
    "        train_predictions.append(n)\n",
    "        \n",
    "test_predictions = []\n",
    "for i in test_preds:\n",
    "    for n in i:\n",
    "        test_predictions.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- build a dataframe where features are lagged timepoints\n",
    "- target is the next feature in the progression  \n",
    "  \n",
    "- specify priors on all coefficients\n",
    "- specify priors on variance of data\n",
    "- plug things into the model \n",
    "- follow pymc3 lesson\n",
    "\n",
    "- goal is actually a posterior predictive\n",
    "- pyflux provides uncertainty bounds (UL + LL)\n",
    "- for a highly generalized bayesian regression try pymc3\n",
    "    - you  need to specify priors and distributions\n",
    "    - begin with something relatively uninformative (broad gaussian, uniform, etc.) \n",
    "    \n",
    "1. write out an equation, which model inteded (ex. regression + variance)\n",
    "2. specify priors for each coefficient, prior on variance\n",
    "    - pymc3 this means creating new objects \n",
    "3. take existing objects/variables that contain priors and build a likelihood distribution with observed data\n",
    "    - prior variables act as parameters\n",
    "    - MCMC\n",
    "4. estimate y-hat and save values\n",
    "    - this is where we capture variance\n",
    "    - write out a function to pull samples from these distributions\n",
    "    - codify the samples pulled, **construct a distribution of y-hat** fitting to obtain bounds and represent uncertainty or anticipated variance\n",
    "        - we can use this to set a confidence interval\n",
    "    - combining these observations to understand uncertainty is where this gets shaky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Regression for Cohort 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -1,039.8, ||grad|| = 0.042853: 100%|| 53/53 [00:00<00:00, 1196.82it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma_log__, beta, intercept]\n",
      "100%|| 2500/2500 [06:03<00:00,  6.88it/s]\n",
      "100%|| 2500/2500 [05:31<00:00,  7.53it/s]\n",
      "The acceptance probability does not match the target. It is 0.9894344705449432, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.9918094634737621, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "logp = -1,623.1, ||grad|| = 243.39: 100%|| 61/61 [00:00<00:00, 1535.76it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma_log__, beta, intercept]\n",
      " 11%|        | 285/2500 [00:00<00:01, 1416.80it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mass matrix contains zeros on the diagonal. Some derivatives might always be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e2586079c228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmap_estimate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_MAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbasic_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbasic_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#set to sample twice so your predictions can be compared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m#takes in inputs (X) and generates an entire range of 2000 predictions (y_hat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, nuts_kwargs, step_kwargs, progressbar, model, random_seed, live_plot, discard_tuned_samples, live_plot_kwargs, compute_convergence_checks, use_mmap, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sequential sampling ({} chains in 1 job)'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0m_print_step_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sample_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0mdiscard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdiscard_tuned_samples\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_sample_many\u001b[0;34m(draws, chain, chains, start, random_seed, step, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         trace = _sample(draws=draws, chain=chain + i, start=start[i],\n\u001b[0;32m--> 510\u001b[0;31m                         step=step, random_seed=random_seed[i], **kwargs)\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(chain, progressbar, random_seed, start, draws, step, trace, tune, model, live_plot, live_plot_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0mstrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlive_plot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlive_plot_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_iter_sample\u001b[0;34m(draws, step, start, trace, chain, tune, model, random_seed)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerates_stats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                 \u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_sampler_stats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0mstrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/step_methods/arraystep.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, point)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerates_stats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0mapoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0mpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logp_dlogp_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_to_full_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/step_methods/hmc/base_hmc.py\u001b[0m in \u001b[0;36mastep\u001b[0;34m(self, q0)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_ok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             raise ValueError('Bad initial energy: %s. The model '\n\u001b[1;32m    117\u001b[0m                              'might be misspecified.' % start.energy)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/step_methods/hmc/quadpotential.py\u001b[0m in \u001b[0;36mraise_ok\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_ok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             raise ValueError('Mass matrix contains zeros on the diagonal. '\n\u001b[0m\u001b[1;32m    191\u001b[0m                              'Some derivatives might always be zero.')\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stds\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mass matrix contains zeros on the diagonal. Some derivatives might always be zero."
     ]
    }
   ],
   "source": [
    "#building lagged dataframe\n",
    "train_yi = []\n",
    "train_preds = []\n",
    "test_yi = []\n",
    "test_preds = []\n",
    "\n",
    "\n",
    "for i in regression_3.index:\n",
    "    dataset = pd.DataFrame()\n",
    "    dataset['target'] = regression_3[regression_3.index==i].T.iloc[:,0]\n",
    "    for n in range(1, 16):\n",
    "        dataset[f'lag{n}'] = dataset['target'].shift(n)\n",
    "    dataset = dataset.loc['2005':]\n",
    "    train = dataset[0:-2]\n",
    "    test = dataset[-2:-1]\n",
    "    \n",
    "    #setting up train, val, test\n",
    "    train_target = train['target']\n",
    "    for y in train_target:\n",
    "        train_yi.append(y)\n",
    "    test_target = test['target']\n",
    "    for h in test_target:\n",
    "        test_yi.append(h)\n",
    "\n",
    "    #setting up x and y for MCMC\n",
    "    y = np.array(train_target).reshape(-1,1)\n",
    "    X = train.drop('target', axis=1)\n",
    "    ss = StandardScaler()\n",
    "    X = ss.fit_transform(X)\n",
    "\n",
    "    #setting standard deviation to feed into the mcmc model\n",
    "    mcmc_std = train_target.std()\n",
    "    \n",
    "    #Building model\n",
    "    basic_model = Model()\n",
    "    with basic_model:\n",
    "        # start by defining distribution for all parameters\n",
    "        # use sd to determine strength of the prior\n",
    "        # big sd is a weak prior\n",
    "        intercept = Normal('intercept', mu=1, sd=mcmc_std)\n",
    "        # the shape on beta is the number of features in the fit\n",
    "        beta = Normal('beta', mu=1, sd=mcmc_std, shape=15)\n",
    "        # sigma is the width of the gaussian around yhat\n",
    "        # (i.e. related to the size of the residuals)\n",
    "        sigma = HalfNormal('sigma', sd=1)\n",
    "\n",
    "        # create a formula for yhat\n",
    "        y_hat = intercept + beta * X\n",
    "\n",
    "        # simulate data as a distribution around yhat\n",
    "        Y_obs = Normal('Y_obs', mu=y_hat, sd=sigma, observed=y)\n",
    "\n",
    "        map_estimate = find_MAP(model=basic_model)\n",
    "    with basic_model:\n",
    "        trace = sample(2000,cores=1) #set to sample twice so your predictions can be compared\n",
    "        \n",
    "    #takes in inputs (X) and generates an entire range of 2000 predictions (y_hat)\n",
    "    preds_train = []\n",
    "    for i in trace:\n",
    "        sigma = i['sigma']\n",
    "        eps = np.random.normal(0, sigma)\n",
    "        y_hat = i['intercept'] + np.matmul(X, i['beta']) + eps\n",
    "        preds_train.append(y_hat)\n",
    "\n",
    "    #generating predictions for the train dataset\n",
    "    avg_preds_train = []\n",
    "    for i in pd.DataFrame(preds_train):\n",
    "        avg_preds_train.append(np.mean(preds_train[i]))\n",
    "    \n",
    "    #setting x and y for test predictions\n",
    "    y_test = np.array(test_target).reshape(-1,1)\n",
    "    X_test = np.array(test.drop('target', axis=1))\n",
    "    ss_test = StandardScaler()\n",
    "    X_test = ss.fit_transform(X_test)\n",
    "    \n",
    "     #generating predictions for the test set\n",
    "    preds_test = []\n",
    "    for i in trace:\n",
    "        sigma = i['sigma']\n",
    "        eps = np.random.normal(0, sigma)\n",
    "        y_hat = i['intercept'] + np.matmul(X_test, i['beta']) + eps\n",
    "        preds_test.append(y_hat)\n",
    "    avg_preds_test = []\n",
    "    for i in pd.DataFrame(preds_test):\n",
    "        avg_preds_test.append(np.mean(preds_test[i]))   \n",
    "    train_preds.append([p for p in avg_preds_train])\n",
    "    test_preds.append([q for q in avg_preds_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = []\n",
    "for i in train_preds:\n",
    "    for n in i:\n",
    "        train_predictions.append(n)\n",
    "        \n",
    "test_predictions = []\n",
    "for i in test_preds:\n",
    "    for n in i:\n",
    "        test_predictions.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|3|Bayesian autoregression|0.24|0.41|48374.17|131346.0|\n"
     ]
    }
   ],
   "source": [
    "print(f'|3|Bayesian autoregression|{np.round(r2_score(train_yi, train_predictions), 2)}|{np.round(r2_score(test_yi, test_predictions), 2)}\\\n",
    "|{np.round(mean_squared_error(train_yi, train_predictions), 2)}|{np.round(mean_squared_error(test_yi, test_predictions), 2)}|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Bayes\n",
    "<a id='tuning'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = 100.99, ||grad|| = 1.3037: 100%|| 15/15 [00:00<00:00, 1157.41it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:04<00:00, 503.43it/s]\n",
      "100%|| 2500/2500 [00:04<00:00, 501.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 1 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -429.95, ||grad|| = 1.5282: 100%|| 37/37 [00:00<00:00, 632.67it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:07<00:00, 356.65it/s]\n",
      "100%|| 2500/2500 [00:06<00:00, 414.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 2 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -410.79, ||grad|| = 0.0014749: 100%|| 42/42 [00:00<00:00, 1594.52it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:08<00:00, 310.00it/s]\n",
      "100%|| 2500/2500 [00:06<00:00, 389.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -123.56, ||grad|| = 31.623: 100%|| 19/19 [00:00<00:00, 1668.55it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:04<00:00, 558.96it/s]\n",
      "100%|| 2500/2500 [00:04<00:00, 591.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 4 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -384.89, ||grad|| = 0.098787: 100%|| 39/39 [00:00<00:00, 1724.58it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:07<00:00, 327.34it/s]\n",
      "100%|| 2500/2500 [00:05<00:00, 417.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 5 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -282.7, ||grad|| = 14.674: 100%|| 31/31 [00:00<00:00, 1583.99it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:06<00:00, 395.13it/s]\n",
      "100%|| 2500/2500 [00:04<00:00, 502.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 6 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -398.18, ||grad|| = 0.00096842: 100%|| 43/43 [00:00<00:00, 1055.13it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:06<00:00, 384.38it/s]\n",
      "100%|| 2500/2500 [00:05<00:00, 424.62it/s]\n",
      "The acceptance probability does not match the target. It is 0.8858404212199025, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 7 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -626.94, ||grad|| = 3.3239: 100%|| 35/35 [00:00<00:00, 1561.11it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:06<00:00, 372.41it/s]\n",
      "100%|| 2500/2500 [00:06<00:00, 414.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 8 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -281.47, ||grad|| = 0.018728: 100%|| 37/37 [00:00<00:00, 1684.50it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:07<00:00, 317.48it/s]\n",
      "100%|| 2500/2500 [00:05<00:00, 476.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 9 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -282.65, ||grad|| = 0.0076006: 100%|| 33/33 [00:00<00:00, 1357.85it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:05<00:00, 454.59it/s]\n",
      "100%|| 2500/2500 [00:05<00:00, 437.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 10 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -430.68, ||grad|| = 0.0075325: 100%|| 43/43 [00:00<00:00, 1567.64it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:09<00:00, 264.63it/s]\n",
      "100%|| 2500/2500 [00:10<00:00, 247.04it/s]\n",
      "The acceptance probability does not match the target. It is 0.8921025299159987, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 11 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -130.86, ||grad|| = 0.017699: 100%|| 34/34 [00:00<00:00, 1153.79it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:07<00:00, 341.96it/s]\n",
      "100%|| 2500/2500 [00:05<00:00, 452.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 12 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -359.46, ||grad|| = 0.49343: 100%|| 38/38 [00:00<00:00, 1536.61it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:08<00:00, 288.33it/s]\n",
      "100%|| 2500/2500 [00:05<00:00, 426.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 13 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -221, ||grad|| = 0.00013617: 100%|| 32/32 [00:00<00:00, 1572.32it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:05<00:00, 462.37it/s]\n",
      "100%|| 2500/2500 [00:04<00:00, 538.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 14 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -437.09, ||grad|| = 0.11971: 100%|| 37/37 [00:00<00:00, 1438.74it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:05<00:00, 424.32it/s]\n",
      "100%|| 2500/2500 [00:04<00:00, 513.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 15 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -476.17, ||grad|| = 0.0035592: 100%|| 34/34 [00:00<00:00, 1615.35it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:06<00:00, 412.65it/s]\n",
      "100%|| 2500/2500 [00:06<00:00, 407.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 16 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -380.86, ||grad|| = 3.4888: 100%|| 39/39 [00:00<00:00, 1455.10it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:08<00:00, 282.94it/s]\n",
      "100%|| 2500/2500 [00:06<00:00, 378.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 17 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -172.18, ||grad|| = 0.20988: 100%|| 26/26 [00:00<00:00, 1430.68it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:07<00:00, 348.37it/s]\n",
      "100%|| 2500/2500 [00:05<00:00, 442.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 18 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -550.1, ||grad|| = 4.1076: 100%|| 38/38 [00:00<00:00, 1341.57it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:08<00:00, 287.76it/s]\n",
      "100%|| 2500/2500 [00:07<00:00, 352.27it/s]\n",
      "The acceptance probability does not match the target. It is 0.882790718384061, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 19 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -309.99, ||grad|| = 0.0026375: 100%|| 32/32 [00:00<00:00, 1233.28it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:08<00:00, 295.85it/s]\n",
      "100%|| 2500/2500 [00:06<00:00, 405.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 20 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -285.67, ||grad|| = 0.10792: 100%|| 35/35 [00:00<00:00, 1391.59it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:06<00:00, 368.39it/s]\n",
      "100%|| 2500/2500 [00:05<00:00, 463.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 21 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -562.28, ||grad|| = 0.026407: 100%|| 44/44 [00:00<00:00, 1473.85it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:08<00:00, 305.63it/s]\n",
      "100%|| 2500/2500 [00:07<00:00, 324.87it/s]\n",
      "The acceptance probability does not match the target. It is 0.8889559012387008, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 22 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -248.91, ||grad|| = 0.017173: 100%|| 34/34 [00:00<00:00, 1455.86it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:07<00:00, 317.44it/s]\n",
      "100%|| 2500/2500 [00:06<00:00, 401.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 23 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -448.81, ||grad|| = 0.011203: 100%|| 45/45 [00:00<00:00, 1278.62it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:07<00:00, 330.57it/s]\n",
      "100%|| 2500/2500 [00:05<00:00, 420.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 24 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -287.67, ||grad|| = 2.4138e-05: 100%|| 32/32 [00:00<00:00, 1537.13it/s]  \n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [sigma, beta, intercept]\n",
      "100%|| 2500/2500 [00:07<00:00, 323.84it/s]\n",
      "100%|| 2500/2500 [00:07<00:00, 335.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country 25 done\n"
     ]
    }
   ],
   "source": [
    "#building lagged dataframe and running it through a regression\n",
    "train_yi = []\n",
    "train_preds_mean = []\n",
    "train_preds_median = []\n",
    "\n",
    "test_yi = []\n",
    "test_preds_mean = []\n",
    "test_preds_median = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in group_1.index:\n",
    "    counter += 1\n",
    "    dataset = pd.DataFrame()\n",
    "    dataset['target'] = group_1[group_1.index==i].T.iloc[:,0]\n",
    "    for n in range(1, 16):\n",
    "        dataset[f'lag{n}'] = dataset['target'].shift(n)\n",
    "    dataset = dataset.loc['2005':]\n",
    "    train = dataset[0:-2]\n",
    "    test = dataset[-2:-1]\n",
    "    \n",
    "    #setting up train, val, test\n",
    "    train_target = train['target']\n",
    "    for y in train_target:\n",
    "        train_yi.append(y)\n",
    "    test_target = test['target']\n",
    "    for h in test_target:\n",
    "        test_yi.append(h)\n",
    "\n",
    "    #setting up x and y for MCMC\n",
    "    y = np.array(train_target).reshape(-1,1)\n",
    "    X = train.drop('target', axis=1)\n",
    "    ss = StandardScaler()\n",
    "    X = ss.fit_transform(X)\n",
    "\n",
    "    #setting standard deviation to feed into the mcmc model\n",
    "    mcmc_std = train_target.std()\n",
    "    \n",
    "    #Building model\n",
    "    basic_model = Model()\n",
    "    with basic_model:\n",
    "        # start by defining distribution for all parameters\n",
    "        # use sd to determine strength of the prior\n",
    "        # big sd is a weak prior\n",
    "        intercept = SkewNormal('intercept', mu=0, sd=mcmc_std, alpha=0.9)\n",
    "        # the shape on beta is the number of features in the fit\n",
    "        beta = SkewNormal('beta', mu=0, sd=mcmc_std, shape=15, alpha=0.9)\n",
    "        # sigma is the width of the gaussian around yhat\n",
    "        # (i.e. related to the size of the residuals)\n",
    "        sigma = HalfNormal('sigma', sd=1)\n",
    "\n",
    "        # create a formula for yhat\n",
    "        y_hat = intercept + beta * X\n",
    "\n",
    "        # simulate data as a distribution around yhat\n",
    "        Y_obs = Normal('Y_obs', mu=y_hat, sd=sigma, observed=y)\n",
    "\n",
    "        map_estimate = find_MAP(model=basic_model)\n",
    "    with basic_model:\n",
    "        trace = sample(2000,cores=1) #set to sample twice so your predictions can be compared\n",
    "        \n",
    "    #takes in inputs (X) and generates an entire range of 2000 predictions (y_hat)\n",
    "    preds_train = []\n",
    "    for i in trace:\n",
    "        sigma = i['sigma']\n",
    "        eps = np.random.normal(0, sigma)\n",
    "        y_hat = i['intercept'] + np.matmul(X, i['beta']) + eps\n",
    "        preds_train.append(y_hat)\n",
    "\n",
    "    #generating predictions for the train dataset\n",
    "    avg_preds_train = []\n",
    "    for i in pd.DataFrame(preds_train):\n",
    "        avg_preds_train.append(np.mean(preds_train[i]))\n",
    "    \n",
    "    #setting x and y for test predictions\n",
    "    y_test = np.array(test_target).reshape(-1,1)\n",
    "    X_test = np.array(test.drop('target', axis=1))\n",
    "    ss_test = StandardScaler()\n",
    "    X_test = ss.fit_transform(X_test)\n",
    "    \n",
    "    #_____________________________________________________________      \n",
    "        \n",
    "    #generating predictions for the train dataset\n",
    "    avg_preds_train = []\n",
    "    for i in pd.DataFrame(preds_train):\n",
    "        train_preds_mean.append(np.mean(pd.DataFrame(preds_train)[i]))\n",
    "        \n",
    "    median_preds_train = []\n",
    "    for i in pd.DataFrame(preds_train):\n",
    "        train_preds_median.append(np.median(pd.DataFrame(preds_train)[i]))\n",
    "\n",
    "    #setting x and y for test predictions\n",
    "    y_test = np.array(test_target).reshape(-1,1)\n",
    "    X_test = np.array(test.drop('target', axis=1))\n",
    "    ss_test = StandardScaler()\n",
    "    X_test = ss.fit_transform(X_test)\n",
    "    \n",
    "    #generating predictions for the test set\n",
    "    preds_test = []\n",
    "    for i in trace:\n",
    "        sigma = i['sigma']\n",
    "        eps = np.random.normal(0, sigma)\n",
    "        y_hat = i['intercept'] + np.matmul(X_test, i['beta']) + eps\n",
    "        preds_test.append(y_hat)\n",
    "        \n",
    "    avg_preds_test = []\n",
    "    for i in pd.DataFrame(preds_test): \n",
    "        test_preds_mean.append(np.mean(pd.DataFrame(preds_test)[i]))\n",
    "        \n",
    "    median_preds_test = []\n",
    "    for i in pd.DataFrame(preds_test): \n",
    "        test_preds_median.append(np.median(pd.DataFrame(preds_test)[i]))\n",
    "        \n",
    "    print(f'country {counter} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Bayesian autoregression|0.78|0.58|39.17|162.7|\n"
     ]
    }
   ],
   "source": [
    "print(f'|Bayesian autoregression|{np.round(r2_score(train_yi, train_predictions), 2)}|{np.round(r2_score(test_yi, test_predictions), 2)}\\\n",
    "|{np.round(mean_squared_error(train_yi, train_predictions), 2)}|{np.round(mean_squared_error(test_yi, test_predictions), 2)}|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = []\n",
    "for i in train_preds:\n",
    "    for n in i:\n",
    "        train_predictions.append(n)\n",
    "        \n",
    "test_predictions = []\n",
    "for i in test_preds:\n",
    "    for n in i:\n",
    "        test_predictions.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#old outputs stored \n",
    "\n",
    "|normal distribution, st.dev = 1.75|0.61|45.87|151.34|    \n",
    "|skew normal, st.dev = 1.75, skew = 1|0.8|0.64|35.97|140.38|  \n",
    "|skew normal, st.dev = 3.5, skew = 1|0.81|0.61|33.37|152.53|  \n",
    "|skew normal, st.dev = 3.5, skew = 1.5|0.78|0.58|39.17|162.7|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
